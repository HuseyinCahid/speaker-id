# ğŸ¤ Model EÄŸitim KÄ±lavuzu

Bu kÄ±lavuz, konuÅŸmacÄ± tanÄ±ma modelini nasÄ±l eÄŸiteceÄŸinizi adÄ±m adÄ±m aÃ§Ä±klar.

## ğŸ“‹ Gereksinimler

1. Python 3.9+ yÃ¼klÃ¼ olmalÄ±
2. Backend baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼klÃ¼ olmalÄ±
3. Ses dosyalarÄ±nÄ±z hazÄ±r olmalÄ±

## ğŸ—‚ï¸ Ses DosyalarÄ± HazÄ±rlama

### KlasÃ¶r YapÄ±sÄ±

Ses dosyalarÄ±nÄ±zÄ± ÅŸu yapÄ±da organize edin:

```
data/
â””â”€â”€ raw/
    â”œâ”€â”€ speaker_01/
    â”‚   â”œâ”€â”€ utt_0001.wav
    â”‚   â”œâ”€â”€ utt_0002.wav
    â”‚   â”œâ”€â”€ utt_0003.wav
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ speaker_02/
    â”‚   â”œâ”€â”€ utt_0001.wav
    â”‚   â”œâ”€â”€ utt_0002.wav
    â”‚   â””â”€â”€ ...
    â””â”€â”€ speaker_03/
        â”œâ”€â”€ utt_0001.wav
        â””â”€â”€ ...
```

### Ses DosyasÄ± FormatÄ±

- **Format**: WAV (Ã¶nerilen)
- **Sample Rate**: 16 kHz (otomatik dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r)
- **Kanal**: Mono (otomatik dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r)
- **SÃ¼re**: En az 1 saniye, ideal 3 saniye

## ğŸš€ Model EÄŸitimi

### 1. Backend BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± YÃ¼kleyin

```bash
cd backend
python -m venv venv
.\venv\Scripts\activate    # Windows
# veya
source venv/bin/activate   # Linux/Mac

pip install -r requirements.txt
```

### 2. EÄŸitim Scriptini Ã‡alÄ±ÅŸtÄ±rÄ±n

```bash
# Projenin ana dizininde (backend/ Ã¼stÃ¼nde)
python train_model.py
```

### 3. Ã‡Ä±ktÄ±larÄ± Ä°nceleyin

Script ÅŸu bilgileri gÃ¶sterecek:

```
ğŸ¤ Speaker Identification Model Training
==================================================

ğŸ“‚ Loading audio files...
Found 3 speakers:
  âœ… speaker_01: 15 files
  âœ… speaker_02: 12 files
  âœ… speaker_03: 18 files

ğŸ“Š Dataset Statistics:
   Total samples: 45
   Features per sample: 1222
   Unique speakers: 3

ğŸ”¬ Train/Test Split:
   Training samples: 36
   Test samples: 9

ğŸ¤– Training SVM model...

ğŸ“ˆ Model Performance:
   Train Accuracy: 0.9722 (97.22%)
   Test Accuracy: 0.8889 (88.89%)

ğŸ’¾ Model saved to: models/svm_speaker_model.pkl
ğŸ“ Speaker labels saved to: models/speaker_labels.txt

âœ… Training complete!
```

### 4. Model DosyalarÄ±nÄ± Kontrol Edin

EÄŸitim tamamlandÄ±ktan sonra:

```
models/
â”œâ”€â”€ svm_speaker_model.pkl    # EÄŸitilmiÅŸ model
â””â”€â”€ speaker_labels.txt        # KonuÅŸmacÄ± etiketleri
```

`speaker_labels.txt` dosyasÄ± ÅŸÃ¶yle gÃ¶rÃ¼nÃ¼r:

```
speaker_01
speaker_02
speaker_03
```

## ğŸ¯ Backend'i Yeniden BaÅŸlatÄ±n

Model eÄŸitildikten sonra backend'i yeniden baÅŸlatÄ±n:

```bash
cd backend
.\venv\Scripts\activate
uvicorn app:app --reload
```

Backend baÅŸlatÄ±lÄ±rken ÅŸu mesajÄ± gÃ¶receksiniz:

```
Loaded model: svm_speaker_model.pkl
Loaded 3 speaker labels
```

## ğŸ§ª Test Edin

### 1. Frontend'i BaÅŸlatÄ±n

```bash
cd frontend
npm run dev
```

### 2. TarayÄ±cÄ±da AÃ§Ä±n

`http://localhost:3000`

### 3. Ses Kaydedin

1. Mikrofon butonuna tÄ±klayÄ±n
2. 3-5 saniye konuÅŸun
3. Durdurun

### 4. SonuÃ§larÄ± GÃ¶rÃ¼n

Model artÄ±k gerÃ§ek tahmin yapacak:

```json
{
  "predictions": [
    {
      "speaker_id": "speaker_01",
      "confidence": 0.87,
      "speaker_name": "speaker_01"
    },
    {
      "speaker_id": "speaker_02",
      "confidence": 0.12,
      "speaker_name": "speaker_02"
    }
  ]
}
```

## ğŸ“Š Model PerformansÄ±

### Ä°yi Performans Ä°Ã§in

- **Her konuÅŸmacÄ± iÃ§in minimum 10-15 Ã¶rnek**
- **Ã–rnekler arasÄ±nda varyasyon** (farklÄ± ifadeler, tonlar)
- **Kaliteli ses kayÄ±tlarÄ±** (az gÃ¼rÃ¼ltÃ¼)
- **TekdÃ¼ze ortam** (aynÄ± mikrofon, odada konuÅŸma)

### Beklenen DoÄŸruluk

- **3-5 konuÅŸmacÄ±**: %85-95 doÄŸruluk
- **10+ konuÅŸmacÄ±**: %75-85 doÄŸruluk
- **Daha fazla Ã¶rnek = Daha iyi performans**

## ğŸ› Sorun Giderme

### "No speaker folders found"

```
âŒ Error: No speaker folders found in data/raw
Expected folders like: speaker_01, speaker_02, etc.
```

**Ã‡Ã¶zÃ¼m**: `data/raw/` iÃ§inde `speaker_XX/` klasÃ¶rleri oluÅŸturun.

### "No WAV files found"

```
âš ï¸  speaker_01: No WAV files found
```

**Ã‡Ã¶zÃ¼m**: Her konuÅŸmacÄ± klasÃ¶rÃ¼ne WAV dosyalarÄ± ekleyin.

### "Failed to process audio"

```
âš ï¸  Failed to process utt_0001.wav: ...
```

**Ã‡Ã¶zÃ¼m**: Dosya bozuk olabilir. BaÅŸka bir format deneyin.

### Model dÃ¼ÅŸÃ¼k doÄŸrulukta

**Ã‡Ã¶zÃ¼m**:
- Daha fazla Ã¶rnek ekleyin
- Ses kalitesini iyileÅŸtirin
- Her konuÅŸmacÄ± iÃ§in farklÄ± ifadeler kaydedin

## ğŸ”„ Modeli GÃ¼ncelleme

Yeni konuÅŸmacÄ± eklemek veya mevcut veri setini geniÅŸletmek iÃ§in:

1. `data/raw/` iÃ§indeki klasÃ¶rleri gÃ¼ncelleyin
2. `python train_model.py` Ã§alÄ±ÅŸtÄ±rÄ±n
3. Backend'i yeniden baÅŸlatÄ±n

## ğŸ“ Notlar

- **SVM Model**: RBF kernel kullanÄ±yor (radial basis function)
- **Feature Type**: MFCC (13 katsayÄ± Ã— ~94 frame = 1,222 Ã¶zellik)
- **Train/Test Split**: %80 eÄŸitim, %20 test (rastgele)
- **Cross-validation**: Åu an yok (eklenebilir)

## ğŸš€ Ä°leri Seviye

### CNN Modeli EÄŸitimi

SVM yerine CNN kullanmak iÃ§in:

1. `notebooks/` klasÃ¶rÃ¼nde Jupyter Notebook aÃ§Ä±n
2. `02_model_training.ipynb` dosyasÄ±nÄ± kullanÄ±n
3. CNN modeli daha hassas ama daha yavaÅŸ

### Model Optimizasyonu

- **Grid Search**: En iyi hyperparameter'larÄ± bul
- **Cross-validation**: Daha gÃ¼venilir performans metrikleri
- **Feature Engineering**: MFCC yerine Mel-spectrogram veya her ikisi

## ğŸ“š Kaynaklar

- [Librosa MFCC DokÃ¼mantasyonu](https://librosa.org/doc/latest/feature.html#mfcc)
- [scikit-learn SVM](https://scikit-learn.org/stable/modules/svm.html)
- [Speaker Recognition Tutorial](https://towardsdatascience.com/speaker-recognition-using-mfcc-8f8e1b3f6e5)

