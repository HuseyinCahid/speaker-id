# ğŸ”„ Cross-Validation ve Hyperparameter Tuning Rehberi

Bu dokÃ¼manda cross-validation ve hyperparameter tuning Ã¶zelliklerinin nasÄ±l kullanÄ±lacaÄŸÄ± aÃ§Ä±klanmaktadÄ±r.

## ğŸ“š Temel Kavramlar

### Cross-Validation (Ã‡apraz DoÄŸrulama)
- Modelin genelleme performansÄ±nÄ± daha gÃ¼venilir ÅŸekilde Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r
- Veri setini k fold'a bÃ¶ler, her fold'u bir kez test seti olarak kullanÄ±r
- Overfitting'i tespit etmeye yardÄ±mcÄ± olur

### Hyperparameter Tuning (Hiperparametre AyarÄ±)
- Modelin en iyi performansÄ± gÃ¶stermesi iÃ§in optimal parametreleri bulur
- Grid Search: TÃ¼m kombinasyonlarÄ± dener (yavaÅŸ ama kapsamlÄ±)
- Random Search: Rastgele kombinasyonlarÄ± dener (hÄ±zlÄ± ama daha az kapsamlÄ±)

---

## ğŸš€ KullanÄ±m

### 1. Sadece Cross-Validation

```bash
python train_model.py --model svm --cv --cv-folds 5
```

**Ã‡Ä±ktÄ±:**
```
ğŸ”„ Cross-Validation: âœ… (5 folds)
ğŸ”„ Performing 5-fold Cross-Validation...
   CV Mean Accuracy: 0.8750 (87.50%)
   CV Std: 0.0234 (2.34%)
   CV Scores: ['0.8500', '0.8800', '0.8700', '0.8900', '0.8850']
```

### 2. Sadece Hyperparameter Tuning

#### Grid Search (TÃ¼m kombinasyonlarÄ± dener)
```bash
python train_model.py --model svm --tune --tuning-method grid
```

#### Random Search (Rastgele kombinasyonlar)
```bash
python train_model.py --model svm --tune --tuning-method random --n-iter 20
```

**Ã‡Ä±ktÄ±:**
```
ğŸ¯ Hyperparameter Tuning: âœ… (grid)
ğŸ¯ Performing Hyperparameter Tuning (grid)...
   Searching through 3 parameter combinations...
   âœ… Best parameters found:
      C: 10
      gamma: 0.1
      kernel: rbf
   Best CV Score: 0.9125 (91.25%)
```

### 3. Her Ä°kisini Birlikte

```bash
python train_model.py --model svm --cv --cv-folds 5 --tune --tuning-method grid
```

Bu durumda:
1. Ã–nce cross-validation yapÄ±lÄ±r (basit model ile)
2. Sonra hyperparameter tuning yapÄ±lÄ±r (iÃ§inde kendi CV'si var)
3. En iyi model final test setinde deÄŸerlendirilir

---

## ğŸ“Š Model BazÄ±nda Hyperparameter Grid'leri

### SVM
```python
{
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],
    'kernel': ['rbf', 'poly', 'sigmoid']
}
```

**Ã–nerilen kullanÄ±m:**
- KÃ¼Ã§Ã¼k veri setleri: Grid Search
- BÃ¼yÃ¼k veri setleri: Random Search (n_iter=30-50)

### Random Forest
```python
{
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
```

**Ã–nerilen kullanÄ±m:**
- Random Search (Ã§ok fazla kombinasyon var)
- n_iter=50-100 Ã¶nerilir

### Neural Network (MLP)
```python
{
    'hidden_layer_sizes': [(64,), (128,), (128, 64), (256, 128)],
    'alpha': [0.0001, 0.001, 0.01],
    'learning_rate_init': [0.0001, 0.001, 0.01],
    'activation': ['relu', 'tanh']
}
```

**Ã–nerilen kullanÄ±m:**
- Random Search (eÄŸitim uzun sÃ¼rer)
- n_iter=20-30 yeterli

### AdaBoost
```python
{
    'n_estimators': [25, 50, 100],
    'learning_rate': [0.5, 1.0, 1.5, 2.0]
}
```

**Ã–nerilen kullanÄ±m:**
- Grid Search (kÃ¼Ã§Ã¼k grid)
- HÄ±zlÄ± sonuÃ§ verir

---

## ğŸ“ Ã–rnek Senaryolar

### Senaryo 1: HÄ±zlÄ± Test (SVM)
```bash
# Sadece CV ile hÄ±zlÄ± deÄŸerlendirme
python train_model.py --model svm --cv --cv-folds 3
```

### Senaryo 2: KapsamlÄ± Optimizasyon (Random Forest)
```bash
# CV + Random Search
python train_model.py \
  --model random_forest \
  --cv --cv-folds 5 \
  --tune --tuning-method random \
  --n-iter 50
```

### Senaryo 3: Neural Network Optimizasyonu
```bash
# Random Search (Grid Ã§ok uzun sÃ¼rer)
python train_model.py \
  --model neural_network \
  --tune --tuning-method random \
  --n-iter 30
```

### Senaryo 4: AdaBoost HÄ±zlÄ± Tuning
```bash
# Grid Search (kÃ¼Ã§Ã¼k grid, hÄ±zlÄ±)
python train_model.py \
  --model adaboost \
  --tune --tuning-method grid
```

---

## ğŸ“ˆ Metadata'da Saklanan Bilgiler

EÄŸer cross-validation veya tuning kullanÄ±lÄ±rsa, metadata dosyasÄ±na ÅŸu bilgiler eklenir:

### Cross-Validation Metadata
```json
{
  "cross_validation": {
    "cv_scores": [0.85, 0.88, 0.87, 0.89, 0.885],
    "cv_mean": 0.875,
    "cv_std": 0.0234,
    "cv_folds": 5
  }
}
```

### Hyperparameter Tuning Metadata
```json
{
  "best_hyperparameters": {
    "C": 10,
    "gamma": 0.1,
    "kernel": "rbf"
  },
  "hyperparameter_tuning_method": "grid"
}
```

---

## âš¡ Performans Ä°puÃ§larÄ±

### 1. Veri Seti Boyutuna GÃ¶re SeÃ§im

**KÃ¼Ã§Ã¼k Veri Seti (< 100 Ã¶rnek):**
- âœ… Cross-validation kullanÄ±n (daha gÃ¼venilir metrikler)
- âœ… Grid Search (kÃ¼Ã§Ã¼k grid'ler iÃ§in hÄ±zlÄ±)
- âš ï¸ Random Search gereksiz (zaten az kombinasyon var)

**Orta Veri Seti (100-500 Ã¶rnek):**
- âœ… Cross-validation (5 folds)
- âœ… Random Search (n_iter=20-30)

**BÃ¼yÃ¼k Veri Seti (> 500 Ã¶rnek):**
- âš ï¸ Cross-validation yavaÅŸ olabilir (3 folds yeterli)
- âœ… Random Search (n_iter=50-100)

### 2. Model Tipine GÃ¶re SeÃ§im

**SVM:**
- Grid Search genellikle hÄ±zlÄ±dÄ±r
- Random Search da iyi Ã§alÄ±ÅŸÄ±r

**Random Forest:**
- Random Search Ã¶nerilir (Ã§ok fazla kombinasyon)
- Grid Search Ã§ok uzun sÃ¼rebilir

**Neural Network:**
- Random Search Ã¶nerilir (eÄŸitim uzun sÃ¼rer)
- Grid Search Ã§ok uzun sÃ¼rebilir

**AdaBoost:**
- Grid Search hÄ±zlÄ± ve yeterli

### 3. Zaman vs. DoÄŸruluk Dengesi

**HÄ±zlÄ± SonuÃ§ Ä°stiyorsanÄ±z:**
```bash
--tune --tuning-method random --n-iter 10
```

**En Ä°yi SonuÃ§ Ä°stiyorsanÄ±z:**
```bash
--tune --tuning-method grid
```

**Dengeli YaklaÅŸÄ±m:**
```bash
--tune --tuning-method random --n-iter 30
```

---

## ğŸ” SonuÃ§larÄ± Yorumlama

### Cross-Validation SonuÃ§larÄ±

**Ä°yi CV SonuÃ§larÄ±:**
- CV Mean: YÃ¼ksek (> 0.85)
- CV Std: DÃ¼ÅŸÃ¼k (< 0.05)
- TÃ¼m fold'lar benzer skorlar

**KÃ¶tÃ¼ CV SonuÃ§larÄ±:**
- CV Mean: DÃ¼ÅŸÃ¼k (< 0.70)
- CV Std: YÃ¼ksek (> 0.10)
- Fold'lar arasÄ±nda bÃ¼yÃ¼k farklar

**Ã‡Ã¶zÃ¼m:**
- Daha fazla veri ekleyin
- Hyperparameter tuning yapÄ±n
- FarklÄ± model deneyin

### Hyperparameter Tuning SonuÃ§larÄ±

**BaÅŸarÄ±lÄ± Tuning:**
- Best CV Score > Train Accuracy (overfitting yok)
- Best CV Score > Test Accuracy (genelleme iyi)
- Parametreler makul aralÄ±klarda

**BaÅŸarÄ±sÄ±z Tuning:**
- Best CV Score Ã§ok dÃ¼ÅŸÃ¼k
- Parametreler ekstrem deÄŸerlerde
- Grid yeterli deÄŸil

**Ã‡Ã¶zÃ¼m:**
- Grid'i geniÅŸletin
- Daha fazla iterasyon (Random Search)
- FarklÄ± model deneyin

---

## ğŸ› Sorun Giderme

### "Grid Search Ã§ok uzun sÃ¼rÃ¼yor"

**Ã‡Ã¶zÃ¼m:**
- Random Search kullanÄ±n
- n_iter'i azaltÄ±n
- Grid'i kÃ¼Ã§Ã¼ltÃ¼n (daha az parametre deÄŸeri)

### "CV skorlarÄ± Ã§ok dÃ¼ÅŸÃ¼k"

**Ã‡Ã¶zÃ¼m:**
- Daha fazla veri ekleyin
- Hyperparameter tuning yapÄ±n
- FarklÄ± model deneyin

### "Best parameters ekstrem deÄŸerlerde"

**Ã‡Ã¶zÃ¼m:**
- Grid'i geniÅŸletin
- Daha fazla veri ekleyin
- Model tipini deÄŸiÅŸtirin

---

## ğŸ“š Ek Kaynaklar

- [scikit-learn Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)
- [Grid Search vs Random Search](https://scikit-learn.org/stable/modules/grid_search.html)
- [Hyperparameter Tuning Best Practices](https://towardsdatascience.com/hyperparameter-tuning-c5619e8e6624)

---

## âœ… Ã–zet

| Ã–zellik | Komut | Ne Zaman KullanÄ±lÄ±r |
|---------|-------|---------------------|
| Cross-Validation | `--cv --cv-folds 5` | GÃ¼venilir performans metrikleri istediÄŸinizde |
| Grid Search | `--tune --tuning-method grid` | KÃ¼Ã§Ã¼k grid'ler, hÄ±zlÄ± modeller |
| Random Search | `--tune --tuning-method random --n-iter 20` | BÃ¼yÃ¼k grid'ler, yavaÅŸ modeller |
| Her Ä°kisi | `--cv --tune` | KapsamlÄ± optimizasyon |

**Ã–nerilen BaÅŸlangÄ±Ã§:**
```bash
python train_model.py --model svm --cv --tune --tuning-method random --n-iter 20
```
